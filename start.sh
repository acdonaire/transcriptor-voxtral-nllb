#!/bin/bash
# =============================================================================
# Script de inicio para Verda Cloud
# Ejecuta ambos contenedores manualmente (sin docker-compose)
# =============================================================================

set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘  ðŸš€ Iniciando Voxtral + NLLB en Verda Cloud                  â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# ConfiguraciÃ³n
VLLM_PORT=8000
GRADIO_PORT=7860
HF_CACHE_DIR="/root/.cache/huggingface"

# =============================================================================
# Paso 1: Iniciar servidor vLLM con Voxtral
# =============================================================================
echo ""
echo "ðŸ“¦ [1/2] Iniciando servidor vLLM con Voxtral-Mini-4B..."
echo "     Puerto: ${VLLM_PORT}"
echo ""

# Instalar dependencias de audio para vLLM
pip install -q soxr librosa soundfile mistral-common>=1.9.0

# Iniciar vLLM en background
VLLM_DISABLE_COMPILE_CACHE=1 vllm serve mistralai/Voxtral-Mini-4B-Realtime-2602 \
    --host 0.0.0.0 \
    --port ${VLLM_PORT} \
    --compilation_config '{"cudagraph_mode": "PIECEWISE"}' \
    --max-model-len 32768 \
    --gpu-memory-utilization 0.65 \
    &

VLLM_PID=$!
echo "     PID de vLLM: ${VLLM_PID}"

# Esperar a que vLLM estÃ© listo
echo "     Esperando a que vLLM estÃ© listo..."
MAX_WAIT=300  # 5 minutos mÃ¡ximo
WAITED=0
while ! curl -s http://localhost:${VLLM_PORT}/health > /dev/null 2>&1; do
    sleep 5
    WAITED=$((WAITED + 5))
    if [ $WAITED -ge $MAX_WAIT ]; then
        echo "âŒ Error: vLLM no respondiÃ³ despuÃ©s de ${MAX_WAIT} segundos"
        exit 1
    fi
    echo "     Esperando... (${WAITED}s)"
done
echo "âœ… vLLM estÃ¡ listo!"

# =============================================================================
# Paso 2: Iniciar aplicaciÃ³n Gradio
# =============================================================================
echo ""
echo "ðŸ“¦ [2/2] Iniciando aplicaciÃ³n Gradio con NLLB..."
echo "     Puerto: ${GRADIO_PORT}"
echo ""

# Instalar dependencias de Gradio
pip install -q gradio>=4.44.0 transformers torch accelerate sentencepiece \
    numpy soxr soundfile librosa websockets

# Configurar variables de entorno
export VLLM_HOST=localhost
export VLLM_PORT=${VLLM_PORT}

# Ejecutar la aplicaciÃ³n Gradio
python /app/app.py &

GRADIO_PID=$!
echo "     PID de Gradio: ${GRADIO_PID}"

# =============================================================================
# Mantener el script corriendo
# =============================================================================
echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘  âœ… Servicios iniciados correctamente                        â•‘"
echo "â•‘                                                              â•‘"
echo "â•‘  ðŸ”— Gradio UI:    http://localhost:${GRADIO_PORT}              â•‘"
echo "â•‘  ðŸ”— vLLM API:     http://localhost:${VLLM_PORT}               â•‘"
echo "â•‘  ðŸ”— Realtime WS:  ws://localhost:${VLLM_PORT}/v1/realtime     â•‘"
echo "â•‘                                                              â•‘"
echo "â•‘  Presiona Ctrl+C para detener todos los servicios            â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# Manejar seÃ±ales de terminaciÃ³n
cleanup() {
    echo ""
    echo "ðŸ›‘ Deteniendo servicios..."
    kill $VLLM_PID 2>/dev/null || true
    kill $GRADIO_PID 2>/dev/null || true
    echo "ðŸ‘‹ Servicios detenidos"
    exit 0
}

trap cleanup SIGINT SIGTERM

# Esperar a que los procesos terminen
wait
