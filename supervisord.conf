# =============================================================================
# Configuración de Supervisor
# Maneja vLLM y Gradio como procesos separados
# =============================================================================

[supervisord]
nodaemon=true
user=root
logfile=/var/log/supervisor/supervisord.log
pidfile=/var/run/supervisord.pid

# =============================================================================
# Proceso 1: vLLM Server con Voxtral
# =============================================================================
[program:vllm]
command=/bin/bash -c "vllm serve mistralai/Voxtral-Mini-4B-Realtime-2602 --host 0.0.0.0 --port 8000 --max-model-len 32768 --gpu-memory-utilization 0.65"
environment=VLLM_DISABLE_COMPILE_CACHE="1"
directory=/app
autostart=true
autorestart=true
startretries=3
startsecs=120
stdout_logfile=/var/log/supervisor/vllm.log
stderr_logfile=/var/log/supervisor/vllm_error.log
priority=1

# =============================================================================
# Proceso 2: Gradio App con NLLB
# =============================================================================
[program:gradio]
command=python /app/app.py
environment=VLLM_HOST="localhost",VLLM_PORT="8000"
directory=/app
autostart=true
autorestart=true
startretries=3
startsecs=10
stdout_logfile=/var/log/supervisor/gradio.log
stderr_logfile=/var/log/supervisor/gradio_error.log
priority=2
# Esperar a que vLLM esté listo antes de iniciar
depends_on=vllm
