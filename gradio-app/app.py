#!/usr/bin/env python3
"""
=============================================================================
AplicaciÃ³n de TranscripciÃ³n en Tiempo Real + TraducciÃ³n
- Voxtral-Mini-4B para transcripciÃ³n (via vLLM WebSocket)
- NLLB-200-distilled-600M para traducciÃ³n a inglÃ©s
=============================================================================
"""

import os
import asyncio
import base64
import json
import queue
import threading
from typing import Optional

import gradio as gr
import numpy as np
import websockets
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

# =============================================================================
# ConfiguraciÃ³n
# =============================================================================

VLLM_HOST = os.environ.get("VLLM_HOST", "localhost")
VLLM_PORT = os.environ.get("VLLM_PORT", "8000")
VOXTRAL_MODEL = "mistralai/Voxtral-Mini-4B-Realtime-2602"
NLLB_MODEL = "facebook/nllb-200-distilled-600M"

SAMPLE_RATE = 16_000  # Voxtral requiere 16kHz

# Mapeo de cÃ³digos de idioma detectados a cÃ³digos NLLB
LANG_TO_NLLB = {
    "es": "spa_Latn",  # EspaÃ±ol
    "en": "eng_Latn",  # InglÃ©s
    "fr": "fra_Latn",  # FrancÃ©s
    "de": "deu_Latn",  # AlemÃ¡n
    "it": "ita_Latn",  # Italiano
    "pt": "por_Latn",  # PortuguÃ©s
    "nl": "nld_Latn",  # HolandÃ©s
    "ru": "rus_Cyrl",  # Ruso
    "zh": "zho_Hans",  # Chino simplificado
    "ja": "jpn_Jpan",  # JaponÃ©s
    "ko": "kor_Hang",  # Coreano
    "ar": "arb_Arab",  # Ãrabe
    "hi": "hin_Deva",  # Hindi
}

# =============================================================================
# Cargar modelo NLLB para traducciÃ³n
# =============================================================================

print(f"ğŸ”„ Cargando modelo de traducciÃ³n: {NLLB_MODEL}")
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"   Dispositivo: {device}")

nllb_tokenizer = AutoTokenizer.from_pretrained(NLLB_MODEL)
nllb_model = AutoModelForSeq2SeqLM.from_pretrained(
    NLLB_MODEL,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32
).to(device)

print("âœ… Modelo NLLB cargado correctamente")

# =============================================================================
# Estado global para WebSocket
# =============================================================================

audio_queue: queue.Queue = queue.Queue()
transcription_text = ""
detected_language = "es"  # Por defecto espaÃ±ol
is_running = False
ws_thread: Optional[threading.Thread] = None


def translate_text(text: str, source_lang: str = "es", target_lang: str = "en") -> str:
    """Traduce texto usando NLLB-200."""
    if not text.strip():
        return ""
    
    # Si el idioma fuente es igual al destino, no traducir
    if source_lang == target_lang:
        return text
    
    # Obtener cÃ³digos NLLB
    src_code = LANG_TO_NLLB.get(source_lang, "spa_Latn")
    tgt_code = LANG_TO_NLLB.get(target_lang, "eng_Latn")
    
    # Configurar idioma fuente en el tokenizer
    nllb_tokenizer.src_lang = src_code
    
    # Tokenizar
    inputs = nllb_tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # Obtener el token ID del idioma destino
    forced_bos_token_id = nllb_tokenizer.convert_tokens_to_ids(tgt_code)
    
    # Generar traducciÃ³n
    with torch.no_grad():
        outputs = nllb_model.generate(
            **inputs,
            forced_bos_token_id=forced_bos_token_id,
            max_new_tokens=256,
            num_beams=4,
            early_stopping=True
        )
    
    # Decodificar
    translation = nllb_tokenizer.decode(outputs[0], skip_special_tokens=True)
    return translation


async def websocket_handler(update_callback):
    """Conecta al WebSocket de vLLM y maneja streaming de audio + transcripciÃ³n."""
    global transcription_text, is_running, detected_language
    
    ws_url = f"ws://{VLLM_HOST}:{VLLM_PORT}/v1/realtime"
    print(f"ğŸ”Œ Conectando a {ws_url}")
    
    try:
        async with websockets.connect(ws_url) as ws:
            # Esperar session.created
            response = json.loads(await ws.recv())
            if response.get("type") == "session.created":
                print(f"âœ… SesiÃ³n creada: {response.get('id')}")
            
            # Configurar modelo
            await ws.send(json.dumps({
                "type": "session.update",
                "model": VOXTRAL_MODEL
            }))
            
            # SeÃ±alar que estamos listos
            await ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
            
            async def send_audio():
                """EnvÃ­a chunks de audio al servidor."""
                while is_running:
                    try:
                        chunk = await asyncio.get_event_loop().run_in_executor(
                            None, lambda: audio_queue.get(timeout=0.1)
                        )
                        await ws.send(json.dumps({
                            "type": "input_audio_buffer.append",
                            "audio": chunk
                        }))
                    except queue.Empty:
                        continue
                    except Exception as e:
                        print(f"Error enviando audio: {e}")
                        break
            
            async def receive_transcription():
                """Recibe transcripciones del servidor."""
                global transcription_text, detected_language
                while is_running:
                    try:
                        response = json.loads(await asyncio.wait_for(ws.recv(), timeout=0.5))
                        
                        if response.get("type") == "transcription.delta":
                            delta = response.get("delta", "")
                            transcription_text += delta
                            
                            # Detectar idioma si estÃ¡ disponible
                            if "language" in response:
                                detected_language = response["language"]
                            
                            # Actualizar UI
                            update_callback(transcription_text, detected_language)
                            
                        elif response.get("type") == "transcription.done":
                            final_text = response.get("text", transcription_text)
                            transcription_text = final_text
                            update_callback(transcription_text, detected_language)
                            
                        elif response.get("type") == "error":
                            print(f"âŒ Error: {response.get('error')}")
                            
                    except asyncio.TimeoutError:
                        continue
                    except Exception as e:
                        if is_running:
                            print(f"Error recibiendo: {e}")
                        break
            
            # Ejecutar envÃ­o y recepciÃ³n en paralelo
            await asyncio.gather(send_audio(), receive_transcription())
            
    except Exception as e:
        print(f"âŒ Error de conexiÃ³n WebSocket: {e}")


def run_websocket_loop(update_callback):
    """Ejecuta el event loop de asyncio en un thread separado."""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(websocket_handler(update_callback))


# =============================================================================
# Interfaz Gradio
# =============================================================================

def process_audio(audio_data, state):
    """Procesa audio del micrÃ³fono y lo envÃ­a al WebSocket."""
    global is_running
    
    if audio_data is None:
        return state.get("transcription", ""), state.get("translation", ""), state
    
    sample_rate, audio_array = audio_data
    
    # Convertir a mono si es estÃ©reo
    if len(audio_array.shape) > 1:
        audio_array = audio_array.mean(axis=1)
    
    # Resamplear a 16kHz si es necesario
    if sample_rate != SAMPLE_RATE:
        import soxr
        audio_array = soxr.resample(audio_array.astype(np.float32), sample_rate, SAMPLE_RATE)
    
    # Normalizar a int16
    if audio_array.dtype == np.float32 or audio_array.dtype == np.float64:
        audio_array = (audio_array * 32767).astype(np.int16)
    elif audio_array.dtype != np.int16:
        audio_array = audio_array.astype(np.int16)
    
    # Convertir a base64 PCM16
    audio_bytes = audio_array.tobytes()
    audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
    
    # Poner en la cola para el WebSocket
    if is_running:
        audio_queue.put(audio_base64)
    
    return state.get("transcription", ""), state.get("translation", ""), state


def start_recording():
    """Inicia la grabaciÃ³n y conexiÃ³n WebSocket."""
    global is_running, ws_thread, transcription_text
    
    if is_running:
        return "â¹ï¸ Ya estÃ¡ grabando...", "", {}
    
    is_running = True
    transcription_text = ""
    
    state = {"transcription": "", "translation": "", "language": "es"}
    
    def update_callback(text, lang):
        state["transcription"] = text
        state["language"] = lang
        # Traducir en tiempo real
        if text.strip():
            state["translation"] = translate_text(text, lang, "en")
    
    # Iniciar WebSocket en thread separado
    ws_thread = threading.Thread(target=run_websocket_loop, args=(update_callback,), daemon=True)
    ws_thread.start()
    
    return "ğŸ¤ Grabando... (habla ahora)", "", state


def stop_recording(state):
    """Detiene la grabaciÃ³n."""
    global is_running
    is_running = False
    
    # Limpiar cola de audio
    while not audio_queue.empty():
        try:
            audio_queue.get_nowait()
        except:
            break
    
    # TraducciÃ³n final
    final_transcription = state.get("transcription", "")
    final_lang = state.get("language", "es")
    final_translation = translate_text(final_transcription, final_lang, "en") if final_transcription else ""
    
    return f"âœ… Detenido. Idioma detectado: {final_lang}", final_transcription, final_translation, state


def update_display(state):
    """Actualiza los campos de texto con el estado actual."""
    return (
        state.get("transcription", ""),
        state.get("translation", ""),
        f"Idioma: {state.get('language', 'es')}"
    )


# =============================================================================
# Crear interfaz
# =============================================================================

with gr.Blocks(
    title="ğŸ¤ TranscripciÃ³n + TraducciÃ³n en Tiempo Real",
    theme=gr.themes.Soft()
) as demo:
    
    gr.Markdown("""
    # ğŸ¤ TranscripciÃ³n y TraducciÃ³n en Tiempo Real
    
    **Modelos utilizados:**
    - **TranscripciÃ³n**: Voxtral-Mini-4B-Realtime (Mistral AI) - 13 idiomas
    - **TraducciÃ³n**: NLLB-200-distilled-600M (Meta) - 200+ idiomas
    
    ---
    """)
    
    state = gr.State({"transcription": "", "translation": "", "language": "es"})
    
    with gr.Row():
        with gr.Column(scale=1):
            status = gr.Textbox(
                label="Estado",
                value="â¸ï¸ Listo para grabar",
                interactive=False
            )
            
            with gr.Row():
                start_btn = gr.Button("ğŸ¤ Iniciar", variant="primary", size="lg")
                stop_btn = gr.Button("â¹ï¸ Detener", variant="stop", size="lg")
            
            audio_input = gr.Audio(
                sources=["microphone"],
                streaming=True,
                label="MicrÃ³fono",
                type="numpy"
            )
            
            lang_display = gr.Textbox(
                label="Idioma Detectado",
                value="EspaÃ±ol (es)",
                interactive=False
            )
    
    with gr.Row():
        with gr.Column():
            transcription_output = gr.Textbox(
                label="ğŸ“ TranscripciÃ³n (idioma original)",
                placeholder="La transcripciÃ³n aparecerÃ¡ aquÃ­...",
                lines=8,
                max_lines=15,
                interactive=False
            )
        
        with gr.Column():
            translation_output = gr.Textbox(
                label="ğŸŒ TraducciÃ³n (InglÃ©s)",
                placeholder="La traducciÃ³n aparecerÃ¡ aquÃ­...",
                lines=8,
                max_lines=15,
                interactive=False
            )
    
    # Eventos
    start_btn.click(
        fn=start_recording,
        inputs=[],
        outputs=[status, transcription_output, state]
    )
    
    stop_btn.click(
        fn=stop_recording,
        inputs=[state],
        outputs=[status, transcription_output, translation_output, state]
    )
    
    audio_input.stream(
        fn=process_audio,
        inputs=[audio_input, state],
        outputs=[transcription_output, translation_output, state]
    )
    
    # ActualizaciÃ³n periÃ³dica del display
    demo.load(
        fn=lambda s: (s.get("transcription", ""), s.get("translation", ""), f"Idioma: {s.get('language', 'es')}"),
        inputs=[state],
        outputs=[transcription_output, translation_output, lang_display],
        every=0.5
    )
    
    gr.Markdown("""
    ---
    ### ğŸ“‹ Instrucciones:
    1. Haz clic en **ğŸ¤ Iniciar** para comenzar
    2. Permite el acceso al micrÃ³fono cuando el navegador lo solicite
    3. Habla en cualquier idioma soportado (espaÃ±ol, inglÃ©s, francÃ©s, etc.)
    4. La transcripciÃ³n aparecerÃ¡ en tiempo real
    5. La traducciÃ³n al inglÃ©s se generarÃ¡ automÃ¡ticamente
    6. Haz clic en **â¹ï¸ Detener** cuando termines
    
    ### ğŸŒ Idiomas soportados para transcripciÃ³n:
    EspaÃ±ol, InglÃ©s, FrancÃ©s, AlemÃ¡n, Italiano, PortuguÃ©s, HolandÃ©s, Ruso, Chino, JaponÃ©s, Coreano, Ãrabe, Hindi
    """)


if __name__ == "__main__":
    print(f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  ğŸ¤ TranscripciÃ³n + TraducciÃ³n en Tiempo Real                â•‘
    â•‘                                                              â•‘
    â•‘  Voxtral-Mini-4B â†’ TranscripciÃ³n                            â•‘
    â•‘  NLLB-200-600M   â†’ TraducciÃ³n                               â•‘
    â•‘                                                              â•‘
    â•‘  vLLM Server: ws://{VLLM_HOST}:{VLLM_PORT}/v1/realtime      â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    demo.queue().launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
